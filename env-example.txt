# Logos Configuration Template
# Copy this file to .env and customize the values for your setup

# =============================================================================
# QDRANT VECTOR DATABASE CONFIGURATION
# =============================================================================

# Qdrant connection settings
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_URL=http://qdrant:6333

# Vector database collections (usually don't need to change)
LOGOS_ESSENCE_COLLECTION=logos_essence
PROJECT_KNOWLEDGE_COLLECTION=project_knowledge
CANON_COLLECTION=canon

# =============================================================================
# LOGOS PERSONALITY CONFIGURATION
# =============================================================================

# Manifesto and personality settings
LOGOS_MANIFESTO_PATH=docs/MANIFESTO.md
LOGOS_PERSONALITY_NAME=Logos
LOGOS_PERSONALITY_BIRTH_DATE=2025-01-01
LOGOS_CREATOR_NAME=Janos Toberling

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Choose your LLM provider: openai, anthropic, ollama, lmstudio, gemini
LLM_PROVIDER=ollama

# Model name (provider-specific)
LLM_MODEL=gpt-4  # For OpenAI
# LLM_MODEL=claude-3-sonnet-20240229  # For Anthropic
# LLM_MODEL=llama2  # For Ollama
# LLM_MODEL=local-model  # For LMStudio
# LLM_MODEL=gemini-pro  # For Google Gemini

# Generation parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# =============================================================================
# EXTERNAL LLM API KEYS (required for cloud providers)
# =============================================================================

# OpenAI API Key (required if LLM_PROVIDER=openai)
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (required if LLM_PROVIDER=anthropic)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google Gemini API Key (required if LLM_PROVIDER=gemini)
# GEMINI_API_KEY=your-gemini-api-key-here

# =============================================================================
# LOCAL LLM ENDPOINTS (for local providers)
# =============================================================================

# Ollama server endpoint (default for local Ollama)
OLLAMA_BASE_URL=http://localhost:11434

# LMStudio server endpoint (default for local LMStudio)
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================

# Embedding model settings
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DEVICE=cpu  # Use 'cuda' for GPU acceleration if available

# =============================================================================
# DATA AND LOGGING PATHS
# =============================================================================

# Data directory (Docker volume compatible)
DATA_DIR=/app/data

# Logs directory (Docker volume compatible)
LOGS_DIR=/app/logs

# =============================================================================
# MCP SERVER CONFIGURATION
# =============================================================================

# MCP server network settings
MCP_HOST=0.0.0.0
MCP_PORT=6334

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG: Detailed diagnostic information
# INFO: General operational messages
# WARNING: Warning conditions that don't stop operation
# ERROR: Error conditions that may affect functionality
# CRITICAL: Critical failures that may stop the system
LOG_LEVEL=INFO

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Python environment settings (usually don't need to change)
PYTHONPATH=/app
PYTHONUNBUFFERED=1

# =============================================================================
# DEPLOYMENT NOTES
# =============================================================================
#
# For Docker deployment:
# - Use docker-compose.yml in logos-core/docker/
# - All paths should use Docker volumes, not local directories
# - Set DATA_DIR and LOGS_DIR to /app/data and /app/logs respectively
#
# For Kubernetes/Portainer deployment:
# - Use PersistentVolumeClaims for data persistence
# - Configure environment variables through ConfigMaps/Secrets
# - Ensure volume mounts use PVC references, not host paths
#
# For local development:
# - Copy this file to .env in the project root
# - Adjust paths to local directories if needed
# - Install dependencies: pip install -r requirements-dev.txt
# - Run: python -m src.main
#
# For testing:
# - Set PYTEST_CURRENT_TEST=1 to skip API key validation
# - Run: python -m pytest
#
# Security notes:
# - Never commit API keys to version control
# - Use Docker secrets or Kubernetes secrets for production
# - Rotate API keys regularly
# - Use environment-specific configurations